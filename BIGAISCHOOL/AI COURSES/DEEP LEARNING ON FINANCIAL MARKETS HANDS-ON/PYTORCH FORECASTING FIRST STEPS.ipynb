{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.chdir(\"../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency</th>\n",
       "      <th>sku</th>\n",
       "      <th>volume</th>\n",
       "      <th>date</th>\n",
       "      <th>industry_volume</th>\n",
       "      <th>soda_volume</th>\n",
       "      <th>avg_max_temp</th>\n",
       "      <th>price_regular</th>\n",
       "      <th>price_actual</th>\n",
       "      <th>discount</th>\n",
       "      <th>...</th>\n",
       "      <th>football_gold_cup</th>\n",
       "      <th>beer_capital</th>\n",
       "      <th>music_fest</th>\n",
       "      <th>discount_in_percent</th>\n",
       "      <th>timeseries</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>month</th>\n",
       "      <th>log_volume</th>\n",
       "      <th>avg_volume_by_sku</th>\n",
       "      <th>avg_volume_by_agency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Agency_25</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>0.5076</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>492612703</td>\n",
       "      <td>718394219</td>\n",
       "      <td>25.845238</td>\n",
       "      <td>1264.162234</td>\n",
       "      <td>1152.473405</td>\n",
       "      <td>111.688829</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>8.835008</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.678062</td>\n",
       "      <td>1225.306376</td>\n",
       "      <td>99.650400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>Agency_29</td>\n",
       "      <td>SKU_02</td>\n",
       "      <td>8.7480</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>498567142</td>\n",
       "      <td>762225057</td>\n",
       "      <td>27.584615</td>\n",
       "      <td>1316.098485</td>\n",
       "      <td>1296.804924</td>\n",
       "      <td>19.293561</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1.465966</td>\n",
       "      <td>177</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2.168825</td>\n",
       "      <td>1634.434615</td>\n",
       "      <td>11.397086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19532</th>\n",
       "      <td>Agency_47</td>\n",
       "      <td>SKU_01</td>\n",
       "      <td>4.9680</td>\n",
       "      <td>2013-09-01</td>\n",
       "      <td>454252482</td>\n",
       "      <td>789624076</td>\n",
       "      <td>30.665957</td>\n",
       "      <td>1269.250000</td>\n",
       "      <td>1266.490490</td>\n",
       "      <td>2.759510</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.217413</td>\n",
       "      <td>322</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1.603017</td>\n",
       "      <td>2625.472644</td>\n",
       "      <td>48.295650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>Agency_53</td>\n",
       "      <td>SKU_07</td>\n",
       "      <td>21.6825</td>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>480693900</td>\n",
       "      <td>791658684</td>\n",
       "      <td>29.197727</td>\n",
       "      <td>1193.842373</td>\n",
       "      <td>1128.124395</td>\n",
       "      <td>65.717978</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>beer_capital</td>\n",
       "      <td>-</td>\n",
       "      <td>5.504745</td>\n",
       "      <td>240</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>3.076505</td>\n",
       "      <td>38.529107</td>\n",
       "      <td>2511.035175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9755</th>\n",
       "      <td>Agency_17</td>\n",
       "      <td>SKU_02</td>\n",
       "      <td>960.5520</td>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>515468092</td>\n",
       "      <td>871204688</td>\n",
       "      <td>23.608120</td>\n",
       "      <td>1338.334248</td>\n",
       "      <td>1232.128069</td>\n",
       "      <td>106.206179</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>music_fest</td>\n",
       "      <td>7.935699</td>\n",
       "      <td>259</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>6.867508</td>\n",
       "      <td>2143.677462</td>\n",
       "      <td>396.022140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7561</th>\n",
       "      <td>Agency_05</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>1184.6535</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>425528909</td>\n",
       "      <td>734443953</td>\n",
       "      <td>28.668254</td>\n",
       "      <td>1369.556376</td>\n",
       "      <td>1161.135214</td>\n",
       "      <td>208.421162</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>15.218151</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7.077206</td>\n",
       "      <td>1566.643589</td>\n",
       "      <td>1881.866367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19204</th>\n",
       "      <td>Agency_11</td>\n",
       "      <td>SKU_05</td>\n",
       "      <td>5.5593</td>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>623319783</td>\n",
       "      <td>1049868815</td>\n",
       "      <td>31.915385</td>\n",
       "      <td>1922.486644</td>\n",
       "      <td>1651.307674</td>\n",
       "      <td>271.178970</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>14.105636</td>\n",
       "      <td>17</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>1.715472</td>\n",
       "      <td>1385.225478</td>\n",
       "      <td>109.699200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8781</th>\n",
       "      <td>Agency_48</td>\n",
       "      <td>SKU_04</td>\n",
       "      <td>4275.1605</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>509281531</td>\n",
       "      <td>892192092</td>\n",
       "      <td>26.767857</td>\n",
       "      <td>1761.258209</td>\n",
       "      <td>1546.059670</td>\n",
       "      <td>215.198539</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>music_fest</td>\n",
       "      <td>12.218455</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8.360577</td>\n",
       "      <td>1757.950603</td>\n",
       "      <td>1925.272108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>Agency_07</td>\n",
       "      <td>SKU_21</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>544203593</td>\n",
       "      <td>761469815</td>\n",
       "      <td>28.987755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>-18.420681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2418.719550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12084</th>\n",
       "      <td>Agency_21</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>46.3608</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>589969396</td>\n",
       "      <td>940912941</td>\n",
       "      <td>32.478910</td>\n",
       "      <td>1675.922116</td>\n",
       "      <td>1413.571789</td>\n",
       "      <td>262.350327</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>15.654088</td>\n",
       "      <td>181</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>3.836454</td>\n",
       "      <td>2034.293024</td>\n",
       "      <td>109.381800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          agency     sku     volume       date  industry_volume  soda_volume  \\\n",
       "291    Agency_25  SKU_03     0.5076 2013-01-01        492612703    718394219   \n",
       "871    Agency_29  SKU_02     8.7480 2015-01-01        498567142    762225057   \n",
       "19532  Agency_47  SKU_01     4.9680 2013-09-01        454252482    789624076   \n",
       "2089   Agency_53  SKU_07    21.6825 2013-10-01        480693900    791658684   \n",
       "9755   Agency_17  SKU_02   960.5520 2015-03-01        515468092    871204688   \n",
       "7561   Agency_05  SKU_03  1184.6535 2014-02-01        425528909    734443953   \n",
       "19204  Agency_11  SKU_05     5.5593 2017-08-01        623319783   1049868815   \n",
       "8781   Agency_48  SKU_04  4275.1605 2013-03-01        509281531    892192092   \n",
       "2540   Agency_07  SKU_21     0.0000 2015-10-01        544203593    761469815   \n",
       "12084  Agency_21  SKU_03    46.3608 2017-04-01        589969396    940912941   \n",
       "\n",
       "       avg_max_temp  price_regular  price_actual    discount  ...  \\\n",
       "291       25.845238    1264.162234   1152.473405  111.688829  ...   \n",
       "871       27.584615    1316.098485   1296.804924   19.293561  ...   \n",
       "19532     30.665957    1269.250000   1266.490490    2.759510  ...   \n",
       "2089      29.197727    1193.842373   1128.124395   65.717978  ...   \n",
       "9755      23.608120    1338.334248   1232.128069  106.206179  ...   \n",
       "7561      28.668254    1369.556376   1161.135214  208.421162  ...   \n",
       "19204     31.915385    1922.486644   1651.307674  271.178970  ...   \n",
       "8781      26.767857    1761.258209   1546.059670  215.198539  ...   \n",
       "2540      28.987755       0.000000      0.000000    0.000000  ...   \n",
       "12084     32.478910    1675.922116   1413.571789  262.350327  ...   \n",
       "\n",
       "       football_gold_cup  beer_capital  music_fest discount_in_percent  \\\n",
       "291                    -             -           -            8.835008   \n",
       "871                    -             -           -            1.465966   \n",
       "19532                  -             -           -            0.217413   \n",
       "2089                   -  beer_capital           -            5.504745   \n",
       "9755                   -             -  music_fest            7.935699   \n",
       "7561                   -             -           -           15.218151   \n",
       "19204                  -             -           -           14.105636   \n",
       "8781                   -             -  music_fest           12.218455   \n",
       "2540                   -             -           -            0.000000   \n",
       "12084                  -             -           -           15.654088   \n",
       "\n",
       "      timeseries time_idx month log_volume avg_volume_by_sku  \\\n",
       "291          228        0     1  -0.678062       1225.306376   \n",
       "871          177       24     1   2.168825       1634.434615   \n",
       "19532        322        8     9   1.603017       2625.472644   \n",
       "2089         240        9    10   3.076505         38.529107   \n",
       "9755         259       26     3   6.867508       2143.677462   \n",
       "7561          21       13     2   7.077206       1566.643589   \n",
       "19204         17       55     8   1.715472       1385.225478   \n",
       "8781         151        2     3   8.360577       1757.950603   \n",
       "2540         300       33    10 -18.420681          0.000000   \n",
       "12084        181       51     4   3.836454       2034.293024   \n",
       "\n",
       "      avg_volume_by_agency  \n",
       "291              99.650400  \n",
       "871              11.397086  \n",
       "19532            48.295650  \n",
       "2089           2511.035175  \n",
       "9755            396.022140  \n",
       "7561           1881.866367  \n",
       "19204           109.699200  \n",
       "8781           1925.272108  \n",
       "2540           2418.719550  \n",
       "12084           109.381800  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_forecasting.data.examples import get_stallion_data\n",
    "\n",
    "data = get_stallion_data()\n",
    "\n",
    "# add time index\n",
    "data[\"time_idx\"] = data[\"date\"].dt.year * 12 + data[\"date\"].dt.month\n",
    "data[\"time_idx\"] -= data[\"time_idx\"].min()\n",
    "\n",
    "# add additional features\n",
    "data[\"month\"] = data.date.dt.month.astype(str).astype(\"category\")  # categories have be strings\n",
    "data[\"log_volume\"] = np.log(data.volume + 1e-8)\n",
    "data[\"avg_volume_by_sku\"] = data.groupby([\"time_idx\", \"sku\"], observed=True).volume.transform(\"mean\")\n",
    "data[\"avg_volume_by_agency\"] = data.groupby([\"time_idx\", \"agency\"], observed=True).volume.transform(\"mean\")\n",
    "\n",
    "# we want to encode special days as one variable and thus need to first reverse one-hot encoding\n",
    "special_days = [\n",
    "    \"easter_day\",\n",
    "    \"good_friday\",\n",
    "    \"new_year\",\n",
    "    \"christmas\",\n",
    "    \"labor_day\",\n",
    "    \"independence_day\",\n",
    "    \"revolution_day_memorial\",\n",
    "    \"regional_games\",\n",
    "    \"fifa_u_17_world_cup\",\n",
    "    \"football_gold_cup\",\n",
    "    \"beer_capital\",\n",
    "    \"music_fest\",\n",
    "]\n",
    "data[special_days] = data[special_days].apply(lambda x: x.map({0: \"-\", 1: x.name})).astype(\"category\")\n",
    "data.sample(10, random_state=521)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>industry_volume</th>\n",
       "      <th>soda_volume</th>\n",
       "      <th>avg_max_temp</th>\n",
       "      <th>price_regular</th>\n",
       "      <th>price_actual</th>\n",
       "      <th>discount</th>\n",
       "      <th>avg_population_2017</th>\n",
       "      <th>avg_yearly_household_income_2017</th>\n",
       "      <th>discount_in_percent</th>\n",
       "      <th>timeseries</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>log_volume</th>\n",
       "      <th>avg_volume_by_sku</th>\n",
       "      <th>avg_volume_by_agency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21000.000000</td>\n",
       "      <td>2.100000e+04</td>\n",
       "      <td>2.100000e+04</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>2.100000e+04</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.00000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1492.403982</td>\n",
       "      <td>5.439214e+08</td>\n",
       "      <td>8.512000e+08</td>\n",
       "      <td>28.612404</td>\n",
       "      <td>1451.536344</td>\n",
       "      <td>1267.347450</td>\n",
       "      <td>184.374146</td>\n",
       "      <td>1.045065e+06</td>\n",
       "      <td>151073.494286</td>\n",
       "      <td>10.574884</td>\n",
       "      <td>174.50000</td>\n",
       "      <td>29.500000</td>\n",
       "      <td>2.464118</td>\n",
       "      <td>1492.403982</td>\n",
       "      <td>1492.403982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2711.496882</td>\n",
       "      <td>6.288022e+07</td>\n",
       "      <td>7.824340e+07</td>\n",
       "      <td>3.972833</td>\n",
       "      <td>683.362417</td>\n",
       "      <td>587.757323</td>\n",
       "      <td>257.469968</td>\n",
       "      <td>9.291926e+05</td>\n",
       "      <td>50409.593114</td>\n",
       "      <td>9.590813</td>\n",
       "      <td>101.03829</td>\n",
       "      <td>17.318515</td>\n",
       "      <td>8.178218</td>\n",
       "      <td>1051.790829</td>\n",
       "      <td>1328.239698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.130518e+08</td>\n",
       "      <td>6.964015e+08</td>\n",
       "      <td>16.731034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3121.690141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.227100e+04</td>\n",
       "      <td>90240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-18.420681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.272388</td>\n",
       "      <td>5.090553e+08</td>\n",
       "      <td>7.890880e+08</td>\n",
       "      <td>25.374816</td>\n",
       "      <td>1311.547158</td>\n",
       "      <td>1178.365653</td>\n",
       "      <td>54.935108</td>\n",
       "      <td>6.018900e+04</td>\n",
       "      <td>110057.000000</td>\n",
       "      <td>3.749628</td>\n",
       "      <td>87.00000</td>\n",
       "      <td>14.750000</td>\n",
       "      <td>2.112923</td>\n",
       "      <td>932.285496</td>\n",
       "      <td>113.420250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>158.436000</td>\n",
       "      <td>5.512000e+08</td>\n",
       "      <td>8.649196e+08</td>\n",
       "      <td>28.479272</td>\n",
       "      <td>1495.174592</td>\n",
       "      <td>1324.695705</td>\n",
       "      <td>138.307225</td>\n",
       "      <td>1.232242e+06</td>\n",
       "      <td>131411.000000</td>\n",
       "      <td>8.948990</td>\n",
       "      <td>174.50000</td>\n",
       "      <td>29.500000</td>\n",
       "      <td>5.065351</td>\n",
       "      <td>1402.305264</td>\n",
       "      <td>1730.529771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1774.793475</td>\n",
       "      <td>5.893715e+08</td>\n",
       "      <td>9.005551e+08</td>\n",
       "      <td>31.568405</td>\n",
       "      <td>1725.652080</td>\n",
       "      <td>1517.311427</td>\n",
       "      <td>272.298630</td>\n",
       "      <td>1.729177e+06</td>\n",
       "      <td>206553.000000</td>\n",
       "      <td>15.647058</td>\n",
       "      <td>262.00000</td>\n",
       "      <td>44.250000</td>\n",
       "      <td>7.481439</td>\n",
       "      <td>2195.362302</td>\n",
       "      <td>2595.316500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22526.610000</td>\n",
       "      <td>6.700157e+08</td>\n",
       "      <td>1.049869e+09</td>\n",
       "      <td>45.290476</td>\n",
       "      <td>19166.625000</td>\n",
       "      <td>4925.404000</td>\n",
       "      <td>19166.625000</td>\n",
       "      <td>3.137874e+06</td>\n",
       "      <td>247220.000000</td>\n",
       "      <td>226.740147</td>\n",
       "      <td>349.00000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>10.022453</td>\n",
       "      <td>4332.363750</td>\n",
       "      <td>5884.717375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             volume  industry_volume   soda_volume  avg_max_temp  \\\n",
       "count  21000.000000     2.100000e+04  2.100000e+04  21000.000000   \n",
       "mean    1492.403982     5.439214e+08  8.512000e+08     28.612404   \n",
       "std     2711.496882     6.288022e+07  7.824340e+07      3.972833   \n",
       "min        0.000000     4.130518e+08  6.964015e+08     16.731034   \n",
       "25%        8.272388     5.090553e+08  7.890880e+08     25.374816   \n",
       "50%      158.436000     5.512000e+08  8.649196e+08     28.479272   \n",
       "75%     1774.793475     5.893715e+08  9.005551e+08     31.568405   \n",
       "max    22526.610000     6.700157e+08  1.049869e+09     45.290476   \n",
       "\n",
       "       price_regular  price_actual      discount  avg_population_2017  \\\n",
       "count   21000.000000  21000.000000  21000.000000         2.100000e+04   \n",
       "mean     1451.536344   1267.347450    184.374146         1.045065e+06   \n",
       "std       683.362417    587.757323    257.469968         9.291926e+05   \n",
       "min         0.000000  -3121.690141      0.000000         1.227100e+04   \n",
       "25%      1311.547158   1178.365653     54.935108         6.018900e+04   \n",
       "50%      1495.174592   1324.695705    138.307225         1.232242e+06   \n",
       "75%      1725.652080   1517.311427    272.298630         1.729177e+06   \n",
       "max     19166.625000   4925.404000  19166.625000         3.137874e+06   \n",
       "\n",
       "       avg_yearly_household_income_2017  discount_in_percent   timeseries  \\\n",
       "count                      21000.000000         21000.000000  21000.00000   \n",
       "mean                      151073.494286            10.574884    174.50000   \n",
       "std                        50409.593114             9.590813    101.03829   \n",
       "min                        90240.000000             0.000000      0.00000   \n",
       "25%                       110057.000000             3.749628     87.00000   \n",
       "50%                       131411.000000             8.948990    174.50000   \n",
       "75%                       206553.000000            15.647058    262.00000   \n",
       "max                       247220.000000           226.740147    349.00000   \n",
       "\n",
       "           time_idx    log_volume  avg_volume_by_sku  avg_volume_by_agency  \n",
       "count  21000.000000  21000.000000       21000.000000          21000.000000  \n",
       "mean      29.500000      2.464118        1492.403982           1492.403982  \n",
       "std       17.318515      8.178218        1051.790829           1328.239698  \n",
       "min        0.000000    -18.420681           0.000000              0.000000  \n",
       "25%       14.750000      2.112923         932.285496            113.420250  \n",
       "50%       29.500000      5.065351        1402.305264           1730.529771  \n",
       "75%       44.250000      7.481439        2195.362302           2595.316500  \n",
       "max       59.000000     10.022453        4332.363750           5884.717375  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency</th>\n",
       "      <th>sku</th>\n",
       "      <th>volume</th>\n",
       "      <th>date</th>\n",
       "      <th>industry_volume</th>\n",
       "      <th>soda_volume</th>\n",
       "      <th>avg_max_temp</th>\n",
       "      <th>price_regular</th>\n",
       "      <th>price_actual</th>\n",
       "      <th>discount</th>\n",
       "      <th>...</th>\n",
       "      <th>football_gold_cup</th>\n",
       "      <th>beer_capital</th>\n",
       "      <th>music_fest</th>\n",
       "      <th>discount_in_percent</th>\n",
       "      <th>timeseries</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>month</th>\n",
       "      <th>log_volume</th>\n",
       "      <th>avg_volume_by_sku</th>\n",
       "      <th>avg_volume_by_agency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agency_22</td>\n",
       "      <td>SKU_01</td>\n",
       "      <td>52.2720</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>492612703</td>\n",
       "      <td>718394219</td>\n",
       "      <td>25.845238</td>\n",
       "      <td>1168.903668</td>\n",
       "      <td>1069.166193</td>\n",
       "      <td>99.737475</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>8.532566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.956461</td>\n",
       "      <td>2613.377501</td>\n",
       "      <td>103.805460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Agency_37</td>\n",
       "      <td>SKU_04</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>492612703</td>\n",
       "      <td>718394219</td>\n",
       "      <td>26.505000</td>\n",
       "      <td>1852.273642</td>\n",
       "      <td>1611.466298</td>\n",
       "      <td>240.807344</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>13.000635</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-18.420681</td>\n",
       "      <td>1361.511918</td>\n",
       "      <td>0.549900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Agency_59</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>812.9214</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>492612703</td>\n",
       "      <td>718394219</td>\n",
       "      <td>22.219737</td>\n",
       "      <td>1270.795012</td>\n",
       "      <td>1197.184260</td>\n",
       "      <td>73.610752</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>5.792496</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.700634</td>\n",
       "      <td>1225.306376</td>\n",
       "      <td>2041.909586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Agency_11</td>\n",
       "      <td>SKU_01</td>\n",
       "      <td>316.4400</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>492612703</td>\n",
       "      <td>718394219</td>\n",
       "      <td>25.360000</td>\n",
       "      <td>1176.155397</td>\n",
       "      <td>1082.757488</td>\n",
       "      <td>93.397909</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>7.940950</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.757134</td>\n",
       "      <td>2613.377501</td>\n",
       "      <td>125.690220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Agency_05</td>\n",
       "      <td>SKU_05</td>\n",
       "      <td>420.9093</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>492612703</td>\n",
       "      <td>718394219</td>\n",
       "      <td>24.079012</td>\n",
       "      <td>1327.003396</td>\n",
       "      <td>1207.822992</td>\n",
       "      <td>119.180404</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>8.981168</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.042417</td>\n",
       "      <td>1179.728165</td>\n",
       "      <td>1638.463500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6765</th>\n",
       "      <td>Agency_08</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>9.8136</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>618073219</td>\n",
       "      <td>919709619</td>\n",
       "      <td>25.373665</td>\n",
       "      <td>1706.410263</td>\n",
       "      <td>1455.262060</td>\n",
       "      <td>251.148203</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>14.717926</td>\n",
       "      <td>336</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>2.283769</td>\n",
       "      <td>2304.827516</td>\n",
       "      <td>76.037400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6764</th>\n",
       "      <td>Agency_60</td>\n",
       "      <td>SKU_05</td>\n",
       "      <td>2235.3495</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>618073219</td>\n",
       "      <td>919709619</td>\n",
       "      <td>23.081069</td>\n",
       "      <td>1898.981558</td>\n",
       "      <td>1528.616113</td>\n",
       "      <td>370.365445</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>19.503372</td>\n",
       "      <td>188</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>7.712153</td>\n",
       "      <td>1530.930920</td>\n",
       "      <td>3311.367493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6763</th>\n",
       "      <td>Agency_19</td>\n",
       "      <td>SKU_05</td>\n",
       "      <td>87.5430</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>618073219</td>\n",
       "      <td>919709619</td>\n",
       "      <td>27.432590</td>\n",
       "      <td>1902.160687</td>\n",
       "      <td>1547.299733</td>\n",
       "      <td>354.860954</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>18.655677</td>\n",
       "      <td>162</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>4.472130</td>\n",
       "      <td>1530.930920</td>\n",
       "      <td>56.557950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6771</th>\n",
       "      <td>Agency_60</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>325.8792</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>618073219</td>\n",
       "      <td>919709619</td>\n",
       "      <td>23.081069</td>\n",
       "      <td>1704.503815</td>\n",
       "      <td>1444.443913</td>\n",
       "      <td>260.059902</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>15.257220</td>\n",
       "      <td>187</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>5.786527</td>\n",
       "      <td>2304.827516</td>\n",
       "      <td>3311.367493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6650</th>\n",
       "      <td>Agency_56</td>\n",
       "      <td>SKU_01</td>\n",
       "      <td>3283.8480</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>618073219</td>\n",
       "      <td>919709619</td>\n",
       "      <td>21.709841</td>\n",
       "      <td>1729.148426</td>\n",
       "      <td>1223.228147</td>\n",
       "      <td>505.920279</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>29.258349</td>\n",
       "      <td>71</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>8.096771</td>\n",
       "      <td>2716.823019</td>\n",
       "      <td>3304.106100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21000 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         agency     sku     volume       date  industry_volume  soda_volume  \\\n",
       "0     Agency_22  SKU_01    52.2720 2013-01-01        492612703    718394219   \n",
       "238   Agency_37  SKU_04     0.0000 2013-01-01        492612703    718394219   \n",
       "237   Agency_59  SKU_03   812.9214 2013-01-01        492612703    718394219   \n",
       "236   Agency_11  SKU_01   316.4400 2013-01-01        492612703    718394219   \n",
       "235   Agency_05  SKU_05   420.9093 2013-01-01        492612703    718394219   \n",
       "...         ...     ...        ...        ...              ...          ...   \n",
       "6765  Agency_08  SKU_03     9.8136 2017-12-01        618073219    919709619   \n",
       "6764  Agency_60  SKU_05  2235.3495 2017-12-01        618073219    919709619   \n",
       "6763  Agency_19  SKU_05    87.5430 2017-12-01        618073219    919709619   \n",
       "6771  Agency_60  SKU_03   325.8792 2017-12-01        618073219    919709619   \n",
       "6650  Agency_56  SKU_01  3283.8480 2017-12-01        618073219    919709619   \n",
       "\n",
       "      avg_max_temp  price_regular  price_actual    discount  ...  \\\n",
       "0        25.845238    1168.903668   1069.166193   99.737475  ...   \n",
       "238      26.505000    1852.273642   1611.466298  240.807344  ...   \n",
       "237      22.219737    1270.795012   1197.184260   73.610752  ...   \n",
       "236      25.360000    1176.155397   1082.757488   93.397909  ...   \n",
       "235      24.079012    1327.003396   1207.822992  119.180404  ...   \n",
       "...            ...            ...           ...         ...  ...   \n",
       "6765     25.373665    1706.410263   1455.262060  251.148203  ...   \n",
       "6764     23.081069    1898.981558   1528.616113  370.365445  ...   \n",
       "6763     27.432590    1902.160687   1547.299733  354.860954  ...   \n",
       "6771     23.081069    1704.503815   1444.443913  260.059902  ...   \n",
       "6650     21.709841    1729.148426   1223.228147  505.920279  ...   \n",
       "\n",
       "      football_gold_cup  beer_capital music_fest discount_in_percent  \\\n",
       "0                     -             -          -            8.532566   \n",
       "238                   -             -          -           13.000635   \n",
       "237                   -             -          -            5.792496   \n",
       "236                   -             -          -            7.940950   \n",
       "235                   -             -          -            8.981168   \n",
       "...                 ...           ...        ...                 ...   \n",
       "6765                  -             -          -           14.717926   \n",
       "6764                  -             -          -           19.503372   \n",
       "6763                  -             -          -           18.655677   \n",
       "6771                  -             -          -           15.257220   \n",
       "6650                  -             -          -           29.258349   \n",
       "\n",
       "     timeseries time_idx month log_volume avg_volume_by_sku  \\\n",
       "0             0        0     1   3.956461       2613.377501   \n",
       "238           5        0     1 -18.420681       1361.511918   \n",
       "237           9        0     1   6.700634       1225.306376   \n",
       "236          14        0     1   5.757134       2613.377501   \n",
       "235          22        0     1   6.042417       1179.728165   \n",
       "...         ...      ...   ...        ...               ...   \n",
       "6765        336       59    12   2.283769       2304.827516   \n",
       "6764        188       59    12   7.712153       1530.930920   \n",
       "6763        162       59    12   4.472130       1530.930920   \n",
       "6771        187       59    12   5.786527       2304.827516   \n",
       "6650         71       59    12   8.096771       2716.823019   \n",
       "\n",
       "     avg_volume_by_agency  \n",
       "0              103.805460  \n",
       "238              0.549900  \n",
       "237           2041.909586  \n",
       "236            125.690220  \n",
       "235           1638.463500  \n",
       "...                   ...  \n",
       "6765            76.037400  \n",
       "6764          3311.367493  \n",
       "6763            56.557950  \n",
       "6771          3311.367493  \n",
       "6650          3304.106100  \n",
       "\n",
       "[21000 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"time_idx\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prediction_length = 6\n",
    "max_encoder_length = 24\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"volume\",\n",
    "    group_ids=[\"agency\", \"sku\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"agency\", \"sku\"],\n",
    "    static_reals=[\"avg_population_2017\", \"avg_yearly_household_income_2017\"],\n",
    "    time_varying_known_categoricals=[\"special_days\", \"month\"],\n",
    "    variable_groups={\"special_days\": special_days},  # group of categorical variables can be treated as one variable\n",
    "    time_varying_known_reals=[\"time_idx\", \"price_regular\", \"discount_in_percent\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\n",
    "        \"volume\",\n",
    "        \"log_volume\",\n",
    "        \"industry_volume\",\n",
    "        \"soda_volume\",\n",
    "        \"avg_max_temp\",\n",
    "        \"avg_volume_by_agency\",\n",
    "        \"avg_volume_by_sku\",\n",
    "    ],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"agency\", \"sku\"], transformation=\"softplus\"\n",
    "    ),  # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "\n",
    "# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "# for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 128  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate baseline mean absolute error, i.e. predict next value as the last available value from the history\n",
    "actuals = torch.cat([y for x, (y, weight) in iter(val_dataloader)])\n",
    "baseline_predictions = Baseline().predict(val_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  84.2400,   84.2400,   84.2400,   84.2400,   84.2400,   84.2400],\n",
       "        [  43.8480,   43.8480,   43.8480,   43.8480,   43.8480,   43.8480],\n",
       "        [  25.7184,   25.7184,   25.7184,   25.7184,   25.7184,   25.7184],\n",
       "        ...,\n",
       "        [2207.3618, 2207.3618, 2207.3618, 2207.3618, 2207.3618, 2207.3618],\n",
       "        [  77.4375,   77.4375,   77.4375,   77.4375,   77.4375,   77.4375],\n",
       "        [   2.5200,    2.5200,    2.5200,    2.5200,    2.5200,    2.5200]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293.0088195800781"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(actuals - baseline_predictions).abs().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 29.7k\n"
     ]
    }
   ],
   "source": [
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,  # set to <= hidden_size\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 1.3 K \n",
      "3  | prescalers                         | ModuleDict                      | 256   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 3.4 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 8.0 K \n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 2.7 K \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \n",
      "11 | lstm_encoder                       | LSTM                            | 2.2 K \n",
      "12 | lstm_decoder                       | LSTM                            | 2.2 K \n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K \n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 576   \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 576   \n",
      "20 | output_layer                       | Linear                          | 119   \n",
      "----------------------------------------------------------------------------------------\n",
      "29.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.7 K    Total params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6319f678ceb4ea7bcc92ec503204a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Finding best initial lr'), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR finder stopped early due to diverging loss.\n",
      "Restored states from the checkpoint file at C:\\Users\\hapir\\PycharmProjects\\QUANTMAVERICK\\lr_find_temp_model.ckpt\n",
      "Failed to compute suggesting for `lr`. There might not be enough points.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hapir\\anaconda3\\envs\\QUANTMAVERICK\\lib\\site-packages\\pytorch_lightning\\tuner\\lr_finder.py\", line 353, in suggestion\n",
      "    min_grad = np.gradient(loss).argmin()\n",
      "  File \"<__array_function__ internals>\", line 5, in gradient\n",
      "  File \"C:\\Users\\hapir\\anaconda3\\envs\\QUANTMAVERICK\\lib\\site-packages\\numpy\\lib\\function_base.py\", line 1052, in gradient\n",
      "    raise ValueError(\n",
      "ValueError: Shape of array too small to calculate a numerical gradient, at least (edge_order + 1) elements are required.\n",
      "Failed to compute suggesting for `lr`. There might not be enough points.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hapir\\anaconda3\\envs\\QUANTMAVERICK\\lib\\site-packages\\pytorch_lightning\\tuner\\lr_finder.py\", line 353, in suggestion\n",
      "    min_grad = np.gradient(loss).argmin()\n",
      "  File \"<__array_function__ internals>\", line 5, in gradient\n",
      "  File \"C:\\Users\\hapir\\anaconda3\\envs\\QUANTMAVERICK\\lib\\site-packages\\numpy\\lib\\function_base.py\", line 1052, in gradient\n",
      "    raise ValueError(\n",
      "ValueError: Shape of array too small to calculate a numerical gradient, at least (edge_order + 1) elements are required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "suggested learning rate: None\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find optimal learning rate\n",
    "res = trainer.tuner.lr_find(\n",
    "    tft,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=10.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    gpus=1,\n",
    "    weights_summary=\"top\",\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 29.7k\n"
     ]
    }
   ],
   "source": [
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 1.3 K \n",
      "3  | prescalers                         | ModuleDict                      | 256   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 3.4 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 8.0 K \n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 2.7 K \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \n",
      "11 | lstm_encoder                       | LSTM                            | 2.2 K \n",
      "12 | lstm_decoder                       | LSTM                            | 2.2 K \n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K \n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 576   \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 576   \n",
      "20 | output_layer                       | Linear                          | 119   \n",
      "----------------------------------------------------------------------------------------\n",
      "29.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.7 K    Total params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eaa22b576534ce4b13eb6c40260de0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
    "# fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-28 10:44:22,709]\u001b[0m A new study created in memory with name: no-name-51390688-7c6c-4fec-aa09-289dec317486\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-28 10:51:44,698]\u001b[0m Trial 0 finished with value: 82.78466033935547 and parameters: {'gradient_clip_val': 0.055623330674825576, 'hidden_size': 23, 'dropout': 0.20313457364165782, 'hidden_continuous_size': 17, 'attention_head_size': 1, 'learning_rate': 0.041049991709581235}. Best is trial 0 with value: 82.78466033935547.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 10:59:14,012]\u001b[0m Trial 1 finished with value: 83.69005584716797 and parameters: {'gradient_clip_val': 0.27874819869552825, 'hidden_size': 84, 'dropout': 0.2526427032058781, 'hidden_continuous_size': 9, 'attention_head_size': 2, 'learning_rate': 0.0045456717816161184}. Best is trial 0 with value: 82.78466033935547.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 10:59:32,327]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 10:59:50,550]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:07:22,949]\u001b[0m Trial 4 finished with value: 79.62007141113281 and parameters: {'gradient_clip_val': 0.17480564795936662, 'hidden_size': 49, 'dropout': 0.20886473571373904, 'hidden_continuous_size': 33, 'attention_head_size': 2, 'learning_rate': 0.04584971208226237}. Best is trial 4 with value: 79.62007141113281.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:07:41,856]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:07:58,802]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:08:17,315]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:08:36,259]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:09:23,131]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:10:06,259]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:10:22,781]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:10:41,999]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:10:58,856]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:11:17,633]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:11:36,788]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:11:53,488]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:12:40,895]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:13:26,892]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:14:15,670]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:21:56,483]\u001b[0m Trial 20 finished with value: 78.44611358642578 and parameters: {'gradient_clip_val': 0.14926976760263563, 'hidden_size': 35, 'dropout': 0.23520407334239096, 'hidden_continuous_size': 31, 'attention_head_size': 3, 'learning_rate': 0.05808225087116388}. Best is trial 20 with value: 78.44611358642578.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:29:40,034]\u001b[0m Trial 21 finished with value: 79.26834869384766 and parameters: {'gradient_clip_val': 0.15112488244328953, 'hidden_size': 35, 'dropout': 0.24470734957157247, 'hidden_continuous_size': 30, 'attention_head_size': 3, 'learning_rate': 0.0608216125170128}. Best is trial 20 with value: 78.44611358642578.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:29:58,874]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:30:45,793]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:31:32,676]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:34:10,811]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 16.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:34:58,172]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:35:17,901]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:36:04,388]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:36:21,527]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:36:40,369]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:36:59,311]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:37:18,018]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:37:36,641]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:37:55,399]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:38:12,506]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:38:59,961]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:39:18,623]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:39:37,474]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:39:56,167]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:40:13,287]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:41:01,204]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:41:20,178]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:42:07,335]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:42:26,180]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:42:44,924]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:43:04,572]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:43:23,870]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:43:42,369]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:44:28,815]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:45:15,821]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:45:34,661]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:45:53,723]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:46:12,326]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:46:31,330]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:47:18,526]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:48:01,133]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:48:20,365]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:49:07,188]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:49:53,882]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:50:12,636]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:58:01,238]\u001b[0m Trial 61 finished with value: 74.87482452392578 and parameters: {'gradient_clip_val': 0.8883226486472555, 'hidden_size': 70, 'dropout': 0.2821042107949444, 'hidden_continuous_size': 54, 'attention_head_size': 3, 'learning_rate': 0.055833071647825534}. Best is trial 61 with value: 74.87482452392578.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:58:20,739]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:59:06,817]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 11:59:25,396]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 12:00:13,950]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 12:00:32,806]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 12:03:06,681]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 16.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 12:03:25,093]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 12:03:43,625]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[32m[I 2021-01-28 12:04:19,813]\u001b[0m Trial 70 finished with value: 80.00797271728516 and parameters: {'gradient_clip_val': 0.5417783910729735, 'hidden_size': 53, 'dropout': 0.29777305428373213, 'hidden_continuous_size': 38, 'attention_head_size': 2, 'learning_rate': 0.03257598283067953}. Best is trial 61 with value: 74.87482452392578.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "# create study\n",
    "study = optimize_hyperparameters(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    model_path=\"optuna_test\",\n",
    "    n_trials=200,\n",
    "    max_epochs=50,\n",
    "    gradient_clip_val_range=(0.01, 1.0),\n",
    "    hidden_size_range=(8, 128),\n",
    "    hidden_continuous_size_range=(8, 128),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.001, 0.1),\n",
    "    dropout_range=(0.1, 0.3),\n",
    "    trainer_kwargs=dict(limit_train_batches=30),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    ")\n",
    "\n",
    "# save study results - also we can resume tuning at a later point in time\n",
    "with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study, fout)\n",
    "\n",
    "# show best hyperparameters\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte mean absolute error on validation set\n",
    "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "predictions = best_tft.predict(val_dataloader)\n",
    "(actuals - predictions).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw predictions are a dictionary from which all kind of information including quantiles can be extracted\n",
    "raw_predictions, x = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(x, raw_predictions, idx=idx, add_loss_to_title=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte metric by which to display\n",
    "predictions = best_tft.predict(val_dataloader)\n",
    "mean_losses = SMAPE(reduction=\"none\")(predictions, actuals).mean(1)\n",
    "indices = mean_losses.argsort(descending=True)  # sort losses\n",
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(x, raw_predictions, idx=indices[idx], add_loss_to_title=SMAPE());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, x = best_tft.predict(val_dataloader, return_x=True)\n",
    "predictions_vs_actuals = best_tft.calculate_prediction_actual_by_variable(x, predictions)\n",
    "best_tft.plot_prediction_actual_by_variable(predictions_vs_actuals);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select last 24 months from data (max_encoder_length is 24)\n",
    "encoder_data = data[lambda x: x.time_idx > x.time_idx.max() - max_encoder_length]\n",
    "\n",
    "# select last known data point and create decoder data from it by repeating it and incrementing the month\n",
    "# in a real world dataset, we should not just forward fill the covariates but specify them to account\n",
    "# for changes in special days and prices\n",
    "last_data = data[lambda x: x.time_idx == x.time_idx.max()]\n",
    "decoder_data = pd.concat(\n",
    "    [last_data.assign(date=lambda x: x.date + pd.offsets.MonthBegin(i)) for i in range(1, max_prediction_length + 1)],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "# add time index consistent with \"data\"\n",
    "decoder_data[\"time_idx\"] = decoder_data[\"date\"].dt.year * 12 + decoder_data[\"date\"].dt.month\n",
    "decoder_data[\"time_idx\"] += encoder_data[\"time_idx\"].max() + 1 - decoder_data[\"time_idx\"].min()\n",
    "\n",
    "# adjust additional time feature(s)\n",
    "decoder_data[\"month\"] = decoder_data.date.dt.month.astype(str).astype(\"category\")  # categories have be strings\n",
    "\n",
    "# combine encoder and decoder data\n",
    "new_prediction_data = pd.concat([encoder_data, decoder_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_raw_predictions, new_x = best_tft.predict(new_prediction_data, mode=\"raw\", return_x=True)\n",
    "\n",
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(new_x, new_raw_predictions, idx=idx, show_future_observed=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation = best_tft.interpret_output(raw_predictions, reduction=\"sum\")\n",
    "best_tft.plot_interpretation(interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency = best_tft.predict_dependency(\n",
    "    val_dataloader.dataset, \"discount_in_percent\", np.linspace(0, 30, 30), show_progress_bar=True, mode=\"dataframe\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting median and 25% and 75% percentile\n",
    "agg_dependency = dependency.groupby(\"discount_in_percent\").normalized_prediction.agg(\n",
    "    median=\"median\", q25=lambda x: x.quantile(0.25), q75=lambda x: x.quantile(0.75)\n",
    ")\n",
    "ax = agg_dependency.plot(y=\"median\")\n",
    "ax.fill_between(agg_dependency.index, agg_dependency.q25, agg_dependency.q75, alpha=0.3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
